{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep lizard pytorch2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPTA3S2UfqiQNbfeHTdjpnQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahmoudta74/Pytorch_Tutorial/blob/master/deep_lizard_pytorch2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHizc6dfv0dz",
        "outputId": "5673cde7-dab2-4da5-8498-ab04f8762524"
      },
      "source": [
        "import torch\r\n",
        "import torchvision\r\n",
        "import torchvision.transforms as transforms\r\n",
        "from torch.utils.data import Dataset\r\n",
        "\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "import torch.optim as optim\r\n",
        "\r\n",
        "torch.set_printoptions(linewidth=120) #Disply Option for output\r\n",
        "torch.set_grad_enabled(True)          # already on by default\\\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.autograd.grad_mode.set_grad_enabled at 0x7f7507e03e50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uppTaVNwByU",
        "outputId": "34ade037-2a2c-439f-f58a-9a8320d2b7c4"
      },
      "source": [
        "print(torch.__version__)\r\n",
        "print(torchvision.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.7.1+cu101\n",
            "0.8.2+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g10IHv3LwEki"
      },
      "source": [
        "def get_num_correct(preds, labels):\r\n",
        "  return preds.argmax(dim=1).eq(labels).sum().item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhXN0R-VwEmy"
      },
      "source": [
        "class Network(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super().__init__()\r\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5) #in_channels=1 (number of color channel)\r\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\r\n",
        "\r\n",
        "        self.fc1 = nn.Linear(in_features=12 * 4 * 4, out_features=120)\r\n",
        "        self.fc2 = nn.Linear(in_features=120, out_features=60)\r\n",
        "        self.out = nn.Linear(in_features=60, out_features=10)\r\n",
        "\r\n",
        "    def forward(self, t):\r\n",
        "      \r\n",
        "      # (1) input layer\r\n",
        "      t = t\r\n",
        "\r\n",
        "      # (2) conv1\r\n",
        "      t = self.conv1(t)\r\n",
        "      t = F.relu(t)             # or---> t = F.relu(self.conv1(t))\r\n",
        "      t = F.max_pool2d(t, kernel_size=2, stride=2)\r\n",
        "      \r\n",
        "      # (3) conv2\r\n",
        "      t = self.conv2(t)\r\n",
        "      t = F.relu(t)\r\n",
        "      t = F.max_pool2d(t, kernel_size=2, stride=2)\r\n",
        "\r\n",
        "      # (4) hidden linear layer\r\n",
        "      t = t.reshape(-1, 12 * 4 * 4) # 12 in the reshaping operation is determined by the number\r\n",
        "      t = self.fc1(t)               # of output channels coming from the previous convolutional layer\r\n",
        "      t = F.relu(t)                 # 4*4 is actually the height and width of each of the 12 output channels.\r\n",
        "                                    # 28*28 reduced to 4*4 by using conv and polling operation.\r\n",
        "\r\n",
        "      # (5) hidden linear layer\r\n",
        "      t = self.fc2(t)\r\n",
        "      t = F.relu(t)\r\n",
        "\r\n",
        "      # (6) output layer\r\n",
        "      t = self.out(t)\r\n",
        "      #t = F.softmax(t, dim=1)\r\n",
        "      \r\n",
        "      return t\r\n",
        "        \r\n",
        "    def __repr__(self):\r\n",
        "      return \"Mahmoudnet\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrZ2ibdVwEpT"
      },
      "source": [
        "train_set = torchvision.datasets.FashionMNIST(\r\n",
        "    root='./data'\r\n",
        "    ,train=True\r\n",
        "    ,download=True\r\n",
        "    ,transform=transforms.Compose([\r\n",
        "        transforms.ToTensor()])\r\n",
        "                                              )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZJxd7VkwErk"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=100, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUEcaCKVwM8b"
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwyBUr_I8p2P"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Upyn39SSwNDa"
      },
      "source": [
        "%matplotlib inline\r\n",
        "\r\n",
        "tb = SummaryWriter()\r\n",
        "\r\n",
        "network = Network()\r\n",
        "images, labels = next(iter(train_loader))\r\n",
        "grid = torchvision.utils.make_grid(images)\r\n",
        "\r\n",
        "tb.add_image('images', grid)  # tag = 'images'\r\n",
        "tb.add_graph(network, images)\r\n",
        "#tb.flush()\r\n",
        "tb.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHsHd1QcwNGK"
      },
      "source": [
        "tensorboard  --logdir=runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBY_VOBCwNI6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77c1acdd-ca33-4746-eb04-0f1eda55e497"
      },
      "source": [
        "network = Network()\r\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=100)\r\n",
        "optimizer = optim.Adam(network.parameters(), lr=0.01)\r\n",
        "\r\n",
        "images, labels = next(iter(train_loader))\r\n",
        "grid = torchvision.utils.make_grid(images)\r\n",
        "\r\n",
        "tb = SummaryWriter()\r\n",
        "tb.add_image('images', grid)\r\n",
        "tb.add_graph(network, images)\r\n",
        "\r\n",
        "for epoch in range(10):\r\n",
        "\r\n",
        "    total_loss = 0\r\n",
        "    total_correct = 0\r\n",
        "\r\n",
        "    for batch in train_loader: # Get Batch\r\n",
        "\r\n",
        "        images, labels = batch \r\n",
        "\r\n",
        "        preds = network(images) # Pass Batch\r\n",
        "        loss = F.cross_entropy(preds, labels) # Calculate Loss\r\n",
        "\r\n",
        "        optimizer.zero_grad()\r\n",
        "        loss.backward() # Calculate Gradients\r\n",
        "        optimizer.step() # Update Weights\r\n",
        "\r\n",
        "        total_loss += loss.item()\r\n",
        "        total_correct += get_num_correct(preds, labels)\r\n",
        "\r\n",
        "\r\n",
        "# Scalar is a number so we add numbers by add_scaler method\r\n",
        "    tb.add_scalar('Loss', total_loss, epoch)\r\n",
        "    tb.add_scalar('Number Correct', total_correct, epoch)\r\n",
        "    tb.add_scalar('Accuracy', total_correct / len(train_set), epoch)\r\n",
        "\r\n",
        "# \r\n",
        "    tb.add_histogram('conv1.bias', network.conv1.bias, epoch)\r\n",
        "    tb.add_histogram('conv1.weight', network.conv1.weight, epoch)\r\n",
        "    tb.add_histogram(\r\n",
        "        'conv1.weight.grad'\r\n",
        "        ,network.conv1.weight.grad\r\n",
        "        ,epoch\r\n",
        "    )\r\n",
        "\r\n",
        "    print(\r\n",
        "        \"epoch\", epoch, \r\n",
        "        \"total_correct:\", total_correct, \r\n",
        "        \"loss:\", total_loss\r\n",
        "    )\r\n",
        "\r\n",
        "tb.close()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0 total_correct: 46652 loss: 352.65682473778725\n",
            "epoch 1 total_correct: 51425 loss: 232.65066657960415\n",
            "epoch 2 total_correct: 51919 loss: 215.44628629088402\n",
            "epoch 3 total_correct: 52135 loss: 210.9139289110899\n",
            "epoch 4 total_correct: 52366 loss: 204.50133468210697\n",
            "epoch 5 total_correct: 52574 loss: 199.82300221920013\n",
            "epoch 6 total_correct: 52540 loss: 198.7275465130806\n",
            "epoch 7 total_correct: 52620 loss: 196.6737863495946\n",
            "epoch 8 total_correct: 52770 loss: 194.8195599168539\n",
            "epoch 9 total_correct: 52853 loss: 190.41903398931026\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPC0WxLbwNLn"
      },
      "source": [
        "tensorboard  --logdir=runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JlI-pGUwNRa"
      },
      "source": [
        "'''\r\n",
        "batch_size = 100\r\n",
        "lr = 0.01\r\n",
        "\r\n",
        "network = Network()\r\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size= batch_size)\r\n",
        "optimizer = optim.Adam(network.parameters(), lr=lr)\r\n",
        "\r\n",
        "images, labels = next(iter(train_loader))\r\n",
        "grid = torchvision.utils.make_grid(images)\r\n",
        "\r\n",
        "\r\n",
        "comment = f'batch_size= {batch_size} lr={lr}'\r\n",
        "tb = SummaryWriter(comment= comment)\r\n",
        "\r\n",
        "tb.add_image('images', grid)\r\n",
        "tb.add_graph(network, images)\r\n",
        "\r\n",
        "for epoch in range(10):\r\n",
        "\r\n",
        "    total_loss = 0\r\n",
        "    total_correct = 0\r\n",
        "\r\n",
        "    for batch in train_loader: # Get Batch\r\n",
        "\r\n",
        "        images, labels = batch \r\n",
        "\r\n",
        "        preds = network(images) # Pass Batch\r\n",
        "        loss = F.cross_entropy(preds, labels) # Calculate Loss\r\n",
        "\r\n",
        "        optimizer.zero_grad()\r\n",
        "        loss.backward() # Calculate Gradients\r\n",
        "        optimizer.step() # Update Weights\r\n",
        "\r\n",
        "        total_loss += loss.item() * batch_size\r\n",
        "        total_correct += get_num_correct(preds, labels)\r\n",
        "\r\n",
        "\r\n",
        "# Scalar is a number so we add numbers by add_scaler method\r\n",
        "    tb.add_scalar('Loss', total_loss, epoch)\r\n",
        "    tb.add_scalar('Number Correct', total_correct, epoch)\r\n",
        "    tb.add_scalar('Accuracy', total_correct / len(train_set), epoch)\r\n",
        "\r\n",
        "# \r\n",
        "#    tb.add_histogram('conv1.bias', network.conv1.bias, epoch)\r\n",
        "#    tb.add_histogram('conv1.weight', network.conv1.weight, epoch)\r\n",
        "#    tb.add_histogram('conv1.weight.grad',network.conv1.weight.grad,epoch)\r\n",
        "\r\n",
        "for name, weight in network.named_parameters():\r\n",
        "  tb.add_histogram(name, weight, epoch)\r\n",
        "  tb.add_histogram(f'{name}.grad', weight.grad, epoch)\r\n",
        "\r\n",
        "\r\n",
        "    print(\r\n",
        "        \"epoch\", epoch, \r\n",
        "        \"total_correct:\", total_correct, \r\n",
        "        \"loss:\", total_loss\r\n",
        "    )\r\n",
        "\r\n",
        "tb.close()\r\n",
        "'''"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17eo_tl6wNUM"
      },
      "source": [
        "batch_size_list = [100, 1000, 10000]\r\n",
        "lr_list = [.01, .001, .0001, .00001]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBMwCXPawNW6"
      },
      "source": [
        "for batch_size in batch_size_list:\r\n",
        "    for lr in lr_list:\r\n",
        "        network = Network()\r\n",
        "\r\n",
        "        train_loader = torch.utils.data.DataLoader(\r\n",
        "            train_set, batch_size=batch_size\r\n",
        "        )\r\n",
        "        optimizer = optim.Adam(\r\n",
        "            network.parameters(), lr=lr\r\n",
        "        )\r\n",
        "\r\n",
        "        images, labels = next(iter(train_loader))\r\n",
        "        grid = torchvision.utils.make_grid(images)\r\n",
        "\r\n",
        "        comment=f' batch_size={batch_size} lr={lr}'\r\n",
        "        tb = SummaryWriter(comment=comment)\r\n",
        "        tb.add_image('images', grid)\r\n",
        "        tb.add_graph(network, images)\r\n",
        "\r\n",
        "        for epoch in range(5):\r\n",
        "            total_loss = 0\r\n",
        "            total_correct = 0\r\n",
        "            for batch in train_loader:\r\n",
        "                images, labels = batch # Get Batch\r\n",
        "                preds = network(images) # Pass Batch\r\n",
        "                loss = F.cross_entropy(preds, labels) # Calculate Loss\r\n",
        "                optimizer.zero_grad() # Zero Gradients\r\n",
        "                loss.backward() # Calculate Gradients\r\n",
        "                optimizer.step() # Update Weights\r\n",
        "\r\n",
        "                total_loss += loss.item() * batch_size\r\n",
        "                total_correct += get_num_correct(preds, labels)\r\n",
        "\r\n",
        "            tb.add_scalar(\r\n",
        "                'Loss', total_loss, epoch\r\n",
        "            )\r\n",
        "            tb.add_scalar(\r\n",
        "                'Number Correct', total_correct, epoch\r\n",
        "            )\r\n",
        "            tb.add_scalar(\r\n",
        "                'Accuracy', total_correct / len(train_set), epoch\r\n",
        "            )\r\n",
        "\r\n",
        "            for name, param in network.named_parameters():\r\n",
        "                tb.add_histogram(name, param, epoch)\r\n",
        "                tb.add_histogram(f'{name}.grad', param.grad, epoch)\r\n",
        "\r\n",
        "            print(\r\n",
        "                \"epoch\", epoch\r\n",
        "                ,\"total_correct:\", total_correct\r\n",
        "                ,\"loss:\", total_loss\r\n",
        "            )  \r\n",
        "        tb.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ke1RSCgUwNZi"
      },
      "source": [
        "################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6aJ20WyKTNa"
      },
      "source": [
        "## Adding More Hyperparameters Without Nesting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3q5q5owwMJb"
      },
      "source": [
        "from itertools import product"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9jV4X1bwMLz"
      },
      "source": [
        "parameters = dict(\r\n",
        "    lr = [.01, .001]\r\n",
        "    ,batch_size = [100, 1000]\r\n",
        "    ,shuffle = [True, False]\r\n",
        ")"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWiF4cc7KptS",
        "outputId": "6b7376c1-c823-44fd-fa8f-3899328a7f34"
      },
      "source": [
        "param_values = [v for v in parameters.values()]\r\n",
        "param_values"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.01, 0.001], [100, 1000], [True, False]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oT8-GJdjKs7R",
        "outputId": "44445434-4e97-4743-9408-1119b120c5ee"
      },
      "source": [
        "for lr, batch_size, shuffle in product(*param_values): \r\n",
        "    print (lr, batch_size, shuffle)\r\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.01 100 True\n",
            "0.01 100 False\n",
            "0.01 1000 True\n",
            "0.01 1000 False\n",
            "0.001 100 True\n",
            "0.001 100 False\n",
            "0.001 1000 True\n",
            "0.001 1000 False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KD6HdNeK5L7",
        "outputId": "631acb75-bae7-4ba0-c143-f1909b21ff83"
      },
      "source": [
        "for lr, batch_size, shuffle in product(*param_values): \r\n",
        "    comment = f' batch_size={batch_size} lr={lr} shuffle={shuffle}'\r\n",
        "\r\n",
        "    train_loader = torch.utils.data.DataLoader(\r\n",
        "        train_set\r\n",
        "        ,batch_size=batch_size\r\n",
        "        ,shuffle=shuffle \r\n",
        "    )\r\n",
        "\r\n",
        "    optimizer = optim.Adam(\r\n",
        "        network.parameters(), lr=lr\r\n",
        "    )\r\n",
        "\r\n",
        "    network = Network()\r\n",
        "\r\n",
        "    images, labels = next(iter(train_loader))\r\n",
        "    grid = torchvision.utils.make_grid(images)\r\n",
        "\r\n",
        "    tb = SummaryWriter(comment=comment)\r\n",
        "    tb.add_image('images', grid)\r\n",
        "    tb.add_graph(network, images)\r\n",
        "\r\n",
        "    for epoch in range(5):\r\n",
        "        total_loss = 0\r\n",
        "        total_correct = 0\r\n",
        "        for batch in train_loader:\r\n",
        "            images, labels = batch # Get Batch\r\n",
        "            preds = network(images) # Pass Batch\r\n",
        "            loss = F.cross_entropy(preds, labels) # Calculate Loss\r\n",
        "            optimizer.zero_grad() # Zero Gradients\r\n",
        "            loss.backward() # Calculate Gradients\r\n",
        "            optimizer.step() # Update Weights\r\n",
        "\r\n",
        "            total_loss += loss.item() * batch_size\r\n",
        "            total_correct += get_num_correct(preds, labels)\r\n",
        "\r\n",
        "        tb.add_scalar('Loss', total_loss, epoch)\r\n",
        "        tb.add_scalar('Number Correct', total_correct, epoch)\r\n",
        "        tb.add_scalar('Accuracy', total_correct / len(train_set), epoch)\r\n",
        "\r\n",
        "        for name, param in network.named_parameters():\r\n",
        "            tb.add_histogram(name, param, epoch)\r\n",
        "            tb.add_histogram(f'{name}.grad', param.grad, epoch)\r\n",
        "\r\n",
        "        print(\r\n",
        "                \"epoch\", epoch\r\n",
        "                ,\"total_correct:\", total_correct\r\n",
        "                ,\"loss:\", total_loss\r\n",
        "            )  \r\n",
        "    tb.close()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0 total_correct: 46663 loss: 35113.365480303764\n",
            "epoch 1 total_correct: 51011 loss: 24234.71935838461\n",
            "epoch 2 total_correct: 51677 loss: 22297.37410545349\n",
            "epoch 3 total_correct: 52204 loss: 21076.16904079914\n",
            "epoch 4 total_correct: 52335 loss: 20573.201489448547\n",
            "epoch 0 total_correct: 47443 loss: 32895.65112888813\n",
            "epoch 1 total_correct: 51602 loss: 22701.62342786789\n",
            "epoch 2 total_correct: 52271 loss: 20664.39869105816\n",
            "epoch 3 total_correct: 52690 loss: 19828.425781428814\n",
            "epoch 4 total_correct: 52864 loss: 19330.202239751816\n",
            "epoch 0 total_correct: 36799 loss: 60367.55186319351\n",
            "epoch 1 total_correct: 47579 loss: 32497.557133436203\n",
            "epoch 2 total_correct: 50254 loss: 26842.14437007904\n",
            "epoch 3 total_correct: 51578 loss: 23296.66566848755\n",
            "epoch 4 total_correct: 52170 loss: 21433.891594409943\n",
            "epoch 0 total_correct: 37901 loss: 58198.84669780731\n",
            "epoch 1 total_correct: 47864 loss: 31861.603021621704\n",
            "epoch 2 total_correct: 50391 loss: 26039.30401802063\n",
            "epoch 3 total_correct: 51626 loss: 22734.14722084999\n",
            "epoch 4 total_correct: 52486 loss: 20409.44731235504\n",
            "epoch 0 total_correct: 42639 loss: 46346.19974195957\n",
            "epoch 1 total_correct: 49325 loss: 28889.44950401783\n",
            "epoch 2 total_correct: 51154 loss: 24580.196651816368\n",
            "epoch 3 total_correct: 51918 loss: 22341.122968494892\n",
            "epoch 4 total_correct: 52433 loss: 20739.821594953537\n",
            "epoch 0 total_correct: 41922 loss: 48442.4017816782\n",
            "epoch 1 total_correct: 47559 loss: 32589.57675397396\n",
            "epoch 2 total_correct: 49525 loss: 28191.349390149117\n",
            "epoch 3 total_correct: 50890 loss: 25230.863627791405\n",
            "epoch 4 total_correct: 51619 loss: 23138.358941674232\n",
            "epoch 0 total_correct: 27210 loss: 91471.0305929184\n",
            "epoch 1 total_correct: 42489 loss: 46702.19266414642\n",
            "epoch 2 total_correct: 44566 loss: 40781.15266561508\n",
            "epoch 3 total_correct: 45630 loss: 37486.713111400604\n",
            "epoch 4 total_correct: 46654 loss: 35241.93185567856\n",
            "epoch 0 total_correct: 31784 loss: 85115.18514156342\n",
            "epoch 1 total_correct: 42836 loss: 44899.172604084015\n",
            "epoch 2 total_correct: 44987 loss: 39331.15965127945\n",
            "epoch 3 total_correct: 46186 loss: 36474.05427694321\n",
            "epoch 4 total_correct: 47032 loss: 34328.9632499218\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkJ06FXdMaOH"
      },
      "source": [
        "tensorboard  --logdir=runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDDQ_VdSQoa9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kl6Mf4eQohT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJh3ziFpQokh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vggY8G_PQpZr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}